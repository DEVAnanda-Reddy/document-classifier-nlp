# ğŸ“„ Document Classifier (NLP | Deep Learning)

A deep learningâ€“based **document classification system** built using **TensorFlow, NLP preprocessing, and Streamlit**.  
This project classifies raw text and `.txt` files into predefined categories and also supports **bulk file sorting into folders** based on predicted labels.

---

## ğŸš€ Features

- âœ… Classify **typed or pasted text**
- âœ… Upload and classify **.txt files**
- âœ… **Batch document classification** from a folder
- âœ… Automatic **file sorting into category folders**
- âœ… Deep learningâ€“based prediction using a trained neural network
- âœ… Interactive **Streamlit web interface**
- âœ… Displays **class probabilities**

---

## ğŸ§  Tech Stack

- **Python 3.10**
- **TensorFlow / Keras**
- **NLTK**
- **Streamlit**
- **NumPy & Pandas**
- **Regex for text cleaning**

---

## ğŸ“‚ Project Structure

```

document-classifier-nlp/
â”‚
â”œâ”€â”€ app.py                          # Streamlit app
â”œâ”€â”€ meta_basic.json                 # Model metadata (categories, max_len)
â”œâ”€â”€ requirements.txt                # Required dependencies
â”œâ”€â”€ Document_Classification.ipynb   # Training notebook
â”œâ”€â”€ basic_dl_doc_classification.ipynb
â”œâ”€â”€ project.ipynb
â”œâ”€â”€ Data/                           # Training data
â”œâ”€â”€ New_Files/                      # New test files
â””â”€â”€ Doc calssifier.png              # App preview image

````

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Create Environment (Recommended)
```bash
conda create -n docclass python=3.10 -y
conda activate docclass
````

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Download NLTK Resources (Auto on first run)

The app automatically downloads:

* stopwords
* punkt
* wordnet

---

## â–¶ï¸ Run the Streamlit App

```bash
python -m streamlit run app.py
```

Then open the browser link shown in terminal, for example:

```
http://localhost:8501
```

---

## ğŸ—ƒï¸ Model & Tokenizer

This project uses:

* A trained deep learning model (`.h5`)
* A saved tokenizer (`.pkl`)

> âš ï¸ These files are **not included in the repository** due to size and security.
> You must place your trained model and tokenizer in the project root to run predictions.

---

## ğŸ“Š Functional Modes

### âœ… Single Text Classification

* Type or paste text
* Upload `.txt` files
* Get predicted category + probability scores

### âœ… Bulk Folder Classification

* Input a folder path
* Automatically sorts `.txt` files into category folders

---

## ğŸ–¼ï¸ Streamlit App Interface Preview

![Streamlit UI Screenshot](https://raw.githubusercontent.com/DEVAnanda-Reddy/document-classifier-nlp/main/UI_ScreenShot.png)


---


---
